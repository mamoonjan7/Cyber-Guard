{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275c9697-e046-4b89-8fee-c9c24c7a1a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f429fbe5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 13:46:46,176 - INFO - Using device: cuda\n",
      "2024-11-14 13:46:47,283 - INFO - Use pytorch device_name: cuda\n",
      "2024-11-14 13:46:47,284 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "2024-11-14 13:46:51,355 - INFO - Preparing data...\n",
      "2024-11-14 13:46:51,356 - INFO - Loading datasets...\n",
      "2024-11-14 13:46:52,185 - INFO - Training set size: 93686\n",
      "2024-11-14 13:46:52,186 - INFO - Test set size: 31229\n",
      "2024-11-14 13:46:52,187 - INFO - \n",
      "Training set label distribution:\n",
      "2024-11-14 13:46:52,192 - INFO - Online Financial Fraud: 65459\n",
      "2024-11-14 13:46:52,193 - INFO - Online and Social Media Related Crime: 12733\n",
      "2024-11-14 13:46:52,193 - INFO - Cyber Attack/ Dependent Crimes: 3704\n",
      "2024-11-14 13:46:52,195 - INFO - RapeGang Rape RGRSexually Abusive Content: 2822\n",
      "2024-11-14 13:46:52,195 - INFO - Any Other Cyber Crime: 2154\n",
      "2024-11-14 13:46:52,196 - INFO - Sexually Obscene material: 1838\n",
      "2024-11-14 13:46:52,196 - INFO - Hacking  Damage to computercomputer system etc: 1710\n",
      "2024-11-14 13:46:52,196 - INFO - Sexually Explicit Act: 1552\n",
      "2024-11-14 13:46:52,196 - INFO - Cryptocurrency Crime: 490\n",
      "2024-11-14 13:46:52,196 - INFO - Online Gambling  Betting: 444\n",
      "2024-11-14 13:46:52,196 - INFO - Child Pornography CPChild Sexual Abuse Material CSAM: 379\n",
      "2024-11-14 13:46:52,196 - INFO - Online Cyber Trafficking: 183\n",
      "2024-11-14 13:46:52,196 - INFO - Cyber Terrorism: 161\n",
      "2024-11-14 13:46:52,200 - INFO - Ransomware: 56\n",
      "2024-11-14 13:46:52,200 - INFO - Report Unlawful Content: 1\n",
      "2024-11-14 13:46:52,212 - WARNING - Found 1 unseen labels in test set: {'Crime Against Women & Children'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057f0cb549d14c7d9e05fd2e5a4126db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kollm\\anaconda3\\envs\\c_gpu\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7acd2654bf4adb8f6ad468d012da9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af38edab15924780ba5bed17c3c4cf5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76011b725acc40ffbe14a52d56e77263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "408892ae18d042f89108bdaeb7a31881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55be7218494f4f02b78de6f720be019b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57af5f69089b4e55a2fdfe7ead5e6bf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29157054b5354924b17eb81ad5d65efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20694e940835489f9a5279230aac2734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36f1ebeea8324c009d9c011b7a2ccec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00fc82131104e7eaf81b54cf0e7fdb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb136c0cb2549299667de4ecb1a1501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e8ac604e9ab4415960e159c2ddf7c36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f855b2f516404f1b9cec0b77e3909d8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bb445f46f5340ba89be843fe03b12a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe2ac27117740aea576e70a9951ddd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 13:46:53,348 - INFO - Similarity between 'Crime Against Women & Children' and 'Online and Social Media Related Crime': 0.4543\n",
      "2024-11-14 13:46:53,349 - INFO - Similarity between 'Crime Against Women & Children' and 'Online Financial Fraud': 0.3502\n",
      "2024-11-14 13:46:53,351 - INFO - Similarity between 'Crime Against Women & Children' and 'Online Gambling  Betting': 0.3267\n",
      "2024-11-14 13:46:53,352 - INFO - Similarity between 'Crime Against Women & Children' and 'RapeGang Rape RGRSexually Abusive Content': 0.2141\n",
      "2024-11-14 13:46:53,353 - INFO - Similarity between 'Crime Against Women & Children' and 'Cyber Attack/ Dependent Crimes': 0.9750\n",
      "2024-11-14 13:46:53,356 - INFO - Similarity between 'Crime Against Women & Children' and 'Cryptocurrency Crime': 0.2977\n",
      "2024-11-14 13:46:53,356 - INFO - Similarity between 'Crime Against Women & Children' and 'Sexually Explicit Act': 0.3848\n",
      "2024-11-14 13:46:53,358 - INFO - Similarity between 'Crime Against Women & Children' and 'Sexually Obscene material': 0.3445\n",
      "2024-11-14 13:46:53,358 - INFO - Similarity between 'Crime Against Women & Children' and 'Hacking  Damage to computercomputer system etc': 0.4549\n",
      "2024-11-14 13:46:53,360 - INFO - Similarity between 'Crime Against Women & Children' and 'Any Other Cyber Crime': 0.2763\n",
      "2024-11-14 13:46:53,362 - INFO - Similarity between 'Crime Against Women & Children' and 'Cyber Terrorism': 0.3570\n",
      "2024-11-14 13:46:53,364 - INFO - Similarity between 'Crime Against Women & Children' and 'Child Pornography CPChild Sexual Abuse Material CSAM': 0.2589\n",
      "2024-11-14 13:46:53,365 - INFO - Similarity between 'Crime Against Women & Children' and 'Online Cyber Trafficking': 0.3132\n",
      "2024-11-14 13:46:53,366 - INFO - Similarity between 'Crime Against Women & Children' and 'Ransomware': 0.3917\n",
      "2024-11-14 13:46:53,367 - INFO - Similarity between 'Crime Against Women & Children' and 'Report Unlawful Content': 0.1180\n",
      "2024-11-14 13:46:53,368 - INFO - Mapping unknown label 'Crime Against Women & Children' to 'Cyber Attack/ Dependent Crimes' with similarity 0.9750\n",
      "2024-11-14 13:46:53,395 - INFO - Number of unique labels: 15\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2024-11-14 13:47:24,422 - INFO - Starting training process...\n",
      "2024-11-14 13:47:24,422 - INFO - Starting training...\n",
      "2024-11-14 13:47:24,422 - INFO - \n",
      "Starting Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 [100/11711] 0.9% | Loss: 2.8414 | Accuracy: 5.25%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 13:50:15,098 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 5.20%\n",
      "Epoch 1/3 [200/11711] 1.7% | Loss: 2.8122 | Accuracy: 6.88%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 13:53:45,089 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 6.90%\n",
      "Epoch 1/3 [300/11711] 2.6% | Loss: 2.7796 | Accuracy: 7.17%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 13:57:31,033 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 7.23%\n",
      "Epoch 1/3 [400/11711] 3.4% | Loss: 2.7369 | Accuracy: 9.12%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 14:01:12,857 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 9.16%\n",
      "Epoch 1/3 [500/11711] 4.3% | Loss: 2.6754 | Accuracy: 18.10%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 14:04:55,113 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 18.16%\n",
      "Epoch 1/3 [600/11711] 5.1% | Loss: 2.5755 | Accuracy: 26.56%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 14:08:34,115 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 26.62%\n",
      "Epoch 1/3 [700/11711] 6.0% | Loss: 2.4492 | Accuracy: 32.54%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 14:12:13,211 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 32.58%\n",
      "Epoch 1/3 [800/11711] 6.8% | Loss: 2.3230 | Accuracy: 37.27%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 14:15:52,077 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 37.30%\n",
      "Epoch 1/3 [900/11711] 7.7% | Loss: 2.2182 | Accuracy: 40.61%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 14:19:31,377 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 40.64%\n",
      "Epoch 1/3 [1000/11711] 8.5% | Loss: 2.1251 | Accuracy: 43.36%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 14:23:11,094 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 43.39%\n",
      "Epoch 1/3 [1100/11711] 9.4% | Loss: 2.0401 | Accuracy: 45.91%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 14:26:50,272 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 45.92%\n",
      "Epoch 1/3 [1200/11711] 10.2% | Loss: 1.9621 | Accuracy: 48.12%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 14:30:30,058 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 48.16%\n",
      "Epoch 1/3 [1300/11711] 11.1% | Loss: 1.8957 | Accuracy: 49.98%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 14:34:09,579 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 50.00%\n",
      "Epoch 1/3 [1400/11711] 12.0% | Loss: 1.8411 | Accuracy: 51.40%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 14:37:48,947 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 51.41%\n",
      "Epoch 1/3 [1500/11711] 12.8% | Loss: 1.7920 | Accuracy: 52.64%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 14:41:28,184 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 52.62%\n",
      "Epoch 1/3 [1600/11711] 13.7% | Loss: 1.7510 | Accuracy: 53.61%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 14:45:07,772 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 53.63%\n",
      "Epoch 1/3 [1700/11711] 14.5% | Loss: 1.7100 | Accuracy: 54.67%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 14:51:32,065 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 54.67%\n",
      "Epoch 1/3 [1800/11711] 15.4% | Loss: 1.6740 | Accuracy: 55.46%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 14:55:12,509 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 55.47%\n",
      "Epoch 1/3 [1900/11711] 16.2% | Loss: 1.6413 | Accuracy: 56.20%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 14:59:05,088 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 56.21%\n",
      "Epoch 1/3 [2000/11711] 17.1% | Loss: 1.6095 | Accuracy: 57.04%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 15:02:49,948 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 57.03%\n",
      "Epoch 1/3 [2100/11711] 17.9% | Loss: 1.5784 | Accuracy: 57.85%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 15:06:42,484 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 57.84%\n",
      "Epoch 1/3 [2200/11711] 18.8% | Loss: 1.5520 | Accuracy: 58.47%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 15:10:35,053 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 58.47%\n",
      "Epoch 1/3 [2300/11711] 19.6% | Loss: 1.5291 | Accuracy: 58.97%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 15:14:27,638 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 58.98%\n",
      "Epoch 1/3 [2400/11711] 20.5% | Loss: 1.5019 | Accuracy: 59.69%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 15:18:20,204 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 59.69%\n",
      "Epoch 1/3 [2500/11711] 21.3% | Loss: 1.4817 | Accuracy: 60.22%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 15:22:12,739 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 60.22%\n",
      "Epoch 1/3 [2600/11711] 22.2% | Loss: 1.4624 | Accuracy: 60.72%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 15:26:05,107 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 60.72%\n",
      "Epoch 1/3 [2700/11711] 23.1% | Loss: 1.4392 | Accuracy: 61.37%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 15:29:58,313 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 61.38%\n",
      "Epoch 1/3 [2800/11711] 23.9% | Loss: 1.4192 | Accuracy: 61.95%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 15:33:51,289 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 61.95%\n",
      "Epoch 1/3 [2900/11711] 24.8% | Loss: 1.3989 | Accuracy: 62.47%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 15:37:44,371 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 62.48%\n",
      "Epoch 1/3 [3000/11711] 25.6% | Loss: 1.3822 | Accuracy: 62.92%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 15:41:37,358 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 62.92%\n",
      "Epoch 1/3 [3100/11711] 26.5% | Loss: 1.3632 | Accuracy: 63.43%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 15:45:23,253 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 63.44%\n",
      "Epoch 1/3 [3200/11711] 27.3% | Loss: 1.3468 | Accuracy: 63.90%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 15:53:59,717 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 63.91%\n",
      "Epoch 1/3 [3300/11711] 28.2% | Loss: 1.3281 | Accuracy: 64.46%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 16:00:02,925 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 64.47%\n",
      "Epoch 1/3 [3400/11711] 29.0% | Loss: 1.3096 | Accuracy: 65.00%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 16:29:46,795 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 65.01%\n",
      "Epoch 1/3 [3500/11711] 29.9% | Loss: 1.2970 | Accuracy: 65.36%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 16:33:26,815 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 65.36%\n",
      "Epoch 1/3 [3600/11711] 30.7% | Loss: 1.2838 | Accuracy: 65.76%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 16:37:08,368 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 65.76%\n",
      "Epoch 1/3 [3700/11711] 31.6% | Loss: 1.2724 | Accuracy: 66.09%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 16:40:49,074 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 66.10%\n",
      "Epoch 1/3 [3800/11711] 32.4% | Loss: 1.2586 | Accuracy: 66.55%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 16:44:37,888 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 66.54%\n",
      "Epoch 1/3 [3900/11711] 33.3% | Loss: 1.2449 | Accuracy: 66.95%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 16:48:20,822 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 66.95%\n",
      "Epoch 1/3 [4000/11711] 34.2% | Loss: 1.2311 | Accuracy: 67.37%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 16:52:13,794 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 67.38%\n",
      "Epoch 1/3 [4100/11711] 35.0% | Loss: 1.2200 | Accuracy: 67.73%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 16:55:53,866 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 67.73%\n",
      "Epoch 1/3 [4200/11711] 35.9% | Loss: 1.2090 | Accuracy: 68.03%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 16:59:36,449 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 68.03%\n",
      "Epoch 1/3 [4300/11711] 36.7% | Loss: 1.1992 | Accuracy: 68.34%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 17:03:19,294 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 68.34%\n",
      "Epoch 1/3 [4400/11711] 37.6% | Loss: 1.1883 | Accuracy: 68.63%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 17:07:00,798 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 68.63%\n",
      "Epoch 1/3 [4500/11711] 38.4% | Loss: 1.1768 | Accuracy: 68.96%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 17:10:40,090 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 68.97%\n",
      "Epoch 1/3 [4600/11711] 39.3% | Loss: 1.1676 | Accuracy: 69.24%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 17:14:19,413 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 69.24%\n",
      "Epoch 1/3 [4700/11711] 40.1% | Loss: 1.1578 | Accuracy: 69.53%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 17:17:58,681 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 69.53%\n",
      "Epoch 1/3 [4800/11711] 41.0% | Loss: 1.1486 | Accuracy: 69.81%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 17:21:38,182 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 69.82%\n",
      "Epoch 1/3 [4900/11711] 41.8% | Loss: 1.1410 | Accuracy: 70.04%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 17:25:18,879 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 70.04%\n",
      "Epoch 1/3 [5000/11711] 42.7% | Loss: 1.1308 | Accuracy: 70.33%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 17:28:58,052 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 70.33%\n",
      "Epoch 1/3 [5100/11711] 43.5% | Loss: 1.1223 | Accuracy: 70.56%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 17:32:37,706 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 70.56%\n",
      "Epoch 1/3 [5200/11711] 44.4% | Loss: 1.1138 | Accuracy: 70.77%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 17:36:17,523 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 70.77%\n",
      "Epoch 1/3 [5300/11711] 45.3% | Loss: 1.1047 | Accuracy: 71.02%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 17:39:57,171 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 71.01%\n",
      "Epoch 1/3 [5400/11711] 46.1% | Loss: 1.0989 | Accuracy: 71.18%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 17:43:36,403 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 71.18%\n",
      "Epoch 1/3 [5500/11711] 47.0% | Loss: 1.0913 | Accuracy: 71.39%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 17:47:15,877 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 71.39%\n",
      "Epoch 1/3 [5600/11711] 47.8% | Loss: 1.0845 | Accuracy: 71.55%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 17:50:55,309 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 71.55%\n",
      "Epoch 1/3 [5700/11711] 48.7% | Loss: 1.0775 | Accuracy: 71.72%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 17:54:35,043 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 71.72%\n",
      "Epoch 1/3 [5800/11711] 49.5% | Loss: 1.0695 | Accuracy: 71.92%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 17:58:14,582 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 71.93%\n",
      "Epoch 1/3 [5900/11711] 50.4% | Loss: 1.0624 | Accuracy: 72.14%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 18:01:54,269 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 72.14%\n",
      "Epoch 1/3 [6000/11711] 51.2% | Loss: 1.0580 | Accuracy: 72.27%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 18:05:33,632 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 72.27%\n",
      "Epoch 1/3 [6100/11711] 52.1% | Loss: 1.0502 | Accuracy: 72.46%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 18:09:12,929 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 72.46%\n",
      "Epoch 1/3 [6200/11711] 52.9% | Loss: 1.0443 | Accuracy: 72.60%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 18:12:52,445 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 72.61%\n",
      "Epoch 1/3 [6300/11711] 53.8% | Loss: 1.0381 | Accuracy: 72.77%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 18:16:44,663 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 72.77%\n",
      "Epoch 1/3 [6400/11711] 54.6% | Loss: 1.0326 | Accuracy: 72.89%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 18:20:37,577 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 72.89%\n",
      "Epoch 1/3 [6500/11711] 55.5% | Loss: 1.0286 | Accuracy: 72.99%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 18:24:30,350 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 72.99%\n",
      "Epoch 1/3 [6600/11711] 56.4% | Loss: 1.0235 | Accuracy: 73.12%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 18:28:23,261 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 73.12%\n",
      "Epoch 1/3 [6700/11711] 57.2% | Loss: 1.0174 | Accuracy: 73.27%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 18:32:16,166 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 73.28%\n",
      "Epoch 1/3 [6800/11711] 58.1% | Loss: 1.0136 | Accuracy: 73.35%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 18:36:09,130 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 73.36%\n",
      "Epoch 1/3 [6900/11711] 58.9% | Loss: 1.0089 | Accuracy: 73.48%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 18:40:01,882 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 73.48%\n",
      "Epoch 1/3 [7000/11711] 59.8% | Loss: 1.0047 | Accuracy: 73.59%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 18:43:54,898 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 73.59%\n",
      "Epoch 1/3 [7100/11711] 60.6% | Loss: 1.0009 | Accuracy: 73.70%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 18:47:47,776 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 73.70%\n",
      "Epoch 1/3 [7200/11711] 61.5% | Loss: 0.9960 | Accuracy: 73.81%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 18:51:40,706 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 73.81%\n",
      "Epoch 1/3 [7300/11711] 62.3% | Loss: 0.9907 | Accuracy: 73.93%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 18:55:33,518 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 73.94%\n",
      "Epoch 1/3 [7400/11711] 63.2% | Loss: 0.9867 | Accuracy: 74.03%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 18:59:26,430 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 74.03%\n",
      "Epoch 1/3 [7500/11711] 64.0% | Loss: 0.9822 | Accuracy: 74.16%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 19:03:19,306 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 74.16%\n",
      "Epoch 1/3 [7600/11711] 64.9% | Loss: 0.9779 | Accuracy: 74.27%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 19:07:01,001 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 74.28%\n",
      "Epoch 1/3 [7700/11711] 65.8% | Loss: 0.9740 | Accuracy: 74.36%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 19:26:04,707 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 74.36%\n",
      "Epoch 1/3 [7800/11711] 66.6% | Loss: 0.9700 | Accuracy: 74.45%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 19:29:43,925 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 74.46%\n",
      "Epoch 1/3 [7900/11711] 67.5% | Loss: 0.9657 | Accuracy: 74.55%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 19:33:23,063 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 74.55%\n",
      "Epoch 1/3 [8000/11711] 68.3% | Loss: 0.9610 | Accuracy: 74.67%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 19:37:02,130 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 74.67%\n",
      "Epoch 1/3 [8100/11711] 69.2% | Loss: 0.9561 | Accuracy: 74.80%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 19:43:36,351 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 74.80%\n",
      "Epoch 1/3 [8200/11711] 70.0% | Loss: 0.9521 | Accuracy: 74.90%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 19:47:23,714 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 74.90%\n",
      "Epoch 1/3 [8300/11711] 70.9% | Loss: 0.9490 | Accuracy: 74.99%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 19:51:16,367 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 74.99%\n",
      "Epoch 1/3 [8400/11711] 71.7% | Loss: 0.9446 | Accuracy: 75.09%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 19:55:09,117 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 75.10%\n",
      "Epoch 1/3 [8500/11711] 72.6% | Loss: 0.9406 | Accuracy: 75.20%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 19:59:01,751 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 75.20%\n",
      "Epoch 1/3 [8600/11711] 73.4% | Loss: 0.9372 | Accuracy: 75.28%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 20:02:54,507 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 75.28%\n",
      "Epoch 1/3 [8700/11711] 74.3% | Loss: 0.9340 | Accuracy: 75.34%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 20:06:47,117 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 75.34%\n",
      "Epoch 1/3 [8800/11711] 75.1% | Loss: 0.9298 | Accuracy: 75.43%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 20:10:39,906 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 75.43%\n",
      "Epoch 1/3 [8900/11711] 76.0% | Loss: 0.9269 | Accuracy: 75.49%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 20:14:32,976 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 75.49%\n",
      "Epoch 1/3 [9000/11711] 76.9% | Loss: 0.9231 | Accuracy: 75.57%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 20:18:26,821 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 75.57%\n",
      "Epoch 1/3 [9100/11711] 77.7% | Loss: 0.9200 | Accuracy: 75.65%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 20:22:06,091 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 75.65%\n",
      "Epoch 1/3 [9200/11711] 78.6% | Loss: 0.9168 | Accuracy: 75.74%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 20:25:45,280 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 75.74%\n",
      "Epoch 1/3 [9300/11711] 79.4% | Loss: 0.9127 | Accuracy: 75.84%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 20:29:24,257 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 75.84%\n",
      "Epoch 1/3 [9400/11711] 80.3% | Loss: 0.9098 | Accuracy: 75.92%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 20:33:03,719 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 75.93%\n",
      "Epoch 1/3 [9500/11711] 81.1% | Loss: 0.9067 | Accuracy: 75.98%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 20:36:43,105 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 75.98%\n",
      "Epoch 1/3 [9600/11711] 82.0% | Loss: 0.9035 | Accuracy: 76.06%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 20:40:22,350 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 76.06%\n",
      "Epoch 1/3 [9700/11711] 82.8% | Loss: 0.9003 | Accuracy: 76.13%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 20:44:01,657 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 76.13%\n",
      "Epoch 1/3 [9800/11711] 83.7% | Loss: 0.8976 | Accuracy: 76.18%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 20:47:44,475 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 76.18%\n",
      "Epoch 1/3 [9900/11711] 84.5% | Loss: 0.8948 | Accuracy: 76.24%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 20:51:25,181 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 76.24%\n",
      "Epoch 1/3 [10000/11711] 85.4% | Loss: 0.8919 | Accuracy: 76.31%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 20:55:04,196 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 76.31%\n",
      "Epoch 1/3 [10100/11711] 86.2% | Loss: 0.8890 | Accuracy: 76.39%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 20:58:46,385 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 76.39%\n",
      "Epoch 1/3 [10200/11711] 87.1% | Loss: 0.8870 | Accuracy: 76.43%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 21:02:39,136 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 76.43%\n",
      "Epoch 1/3 [10300/11711] 88.0% | Loss: 0.8843 | Accuracy: 76.49%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 21:06:31,955 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 76.49%\n",
      "Epoch 1/3 [10400/11711] 88.8% | Loss: 0.8816 | Accuracy: 76.56%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 21:10:24,836 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 76.56%\n",
      "Epoch 1/3 [10500/11711] 89.7% | Loss: 0.8794 | Accuracy: 76.63%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 21:14:17,723 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 76.63%\n",
      "Epoch 1/3 [10600/11711] 90.5% | Loss: 0.8768 | Accuracy: 76.68%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 21:18:10,487 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 76.68%\n",
      "Epoch 1/3 [10700/11711] 91.4% | Loss: 0.8739 | Accuracy: 76.75%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-15 21:41:29,619 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 76.76%\n",
      "Epoch 1/3 [10800/11711] 92.2% | Loss: 0.8726 | Accuracy: 76.78%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 12:00:34,740 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 76.78%\n",
      "Epoch 1/3 [10900/11711] 93.1% | Loss: 0.8699 | Accuracy: 76.84%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 12:04:32,518 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 76.84%\n",
      "Epoch 1/3 [11000/11711] 93.9% | Loss: 0.8675 | Accuracy: 76.90%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 12:08:34,804 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 76.90%\n",
      "Epoch 1/3 [11100/11711] 94.8% | Loss: 0.8652 | Accuracy: 76.95%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 12:12:43,073 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 76.95%\n",
      "Epoch 1/3 [11200/11711] 95.6% | Loss: 0.8625 | Accuracy: 77.01%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 12:16:46,424 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 77.01%\n",
      "Epoch 1/3 [11300/11711] 96.5% | Loss: 0.8602 | Accuracy: 77.07%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 12:20:56,849 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 77.07%\n",
      "Epoch 1/3 [11400/11711] 97.3% | Loss: 0.8580 | Accuracy: 77.12%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 12:25:08,860 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 77.13%\n",
      "Epoch 1/3 [11500/11711] 98.2% | Loss: 0.8556 | Accuracy: 77.19%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 12:29:08,226 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 77.19%\n",
      "Epoch 1/3 [11600/11711] 99.1% | Loss: 0.8535 | Accuracy: 77.24%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 12:33:14,107 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 77.25%\n",
      "Epoch 1/3 [11700/11711] 99.9% | Loss: 0.8514 | Accuracy: 77.29%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 12:37:25,214 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 77.29%\n",
      "Epoch 1/3 [11710/11711] 100.0% | Loss: 0.8511 | Accuracy: 77.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 15:58:21,687 - INFO - Epoch 1 completed. Validation accuracy: 77.52%\n",
      "2024-11-16 15:58:23,060 - INFO - Model saved to checkpoint_epoch_1.pt\n",
      "2024-11-16 15:58:23,061 - INFO - Checkpoint saved: checkpoint_epoch_1.pt\n",
      "2024-11-16 15:58:23,062 - INFO - \n",
      "Starting Epoch 2/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 [100/11711] 0.9% | Loss: 0.6135 | Accuracy: 81.62%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 16:02:33,935 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 81.68%\n",
      "Epoch 2/3 [200/11711] 1.7% | Loss: 0.6162 | Accuracy: 82.12%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 16:06:49,199 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 82.09%\n",
      "Epoch 2/3 [300/11711] 2.6% | Loss: 0.5979 | Accuracy: 82.25%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 16:10:45,623 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 82.27%\n",
      "Epoch 2/3 [400/11711] 3.4% | Loss: 0.6030 | Accuracy: 82.50%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 16:14:29,681 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 82.54%\n",
      "Epoch 2/3 [800/11711] 6.8% | Loss: 0.6005 | Accuracy: 82.69%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 16:56:33,296 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 82.66%\n",
      "Epoch 2/3 [900/11711] 7.7% | Loss: 0.6028 | Accuracy: 82.81%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 17:00:49,387 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 82.80%\n",
      "Epoch 2/3 [1100/11711] 9.4% | Loss: 0.6012 | Accuracy: 82.89%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 17:09:24,739 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 82.88%\n",
      "Epoch 2/3 [1300/11711] 11.1% | Loss: 0.6020 | Accuracy: 82.90%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 17:17:55,130 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 82.91%\n",
      "Epoch 2/3 [1400/11711] 12.0% | Loss: 0.6007 | Accuracy: 82.97%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 17:22:10,422 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 82.98%\n",
      "Epoch 2/3 [1500/11711] 12.8% | Loss: 0.5995 | Accuracy: 83.04%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 17:26:34,731 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 83.04%\n",
      "Epoch 2/3 [1800/11711] 15.4% | Loss: 0.5964 | Accuracy: 83.06%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 17:39:29,560 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 83.06%\n",
      "Epoch 2/3 [1900/11711] 16.2% | Loss: 0.5922 | Accuracy: 83.17%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 17:43:44,921 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 83.18%\n",
      "Epoch 2/3 [2500/11711] 21.3% | Loss: 0.5911 | Accuracy: 83.21%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 18:10:14,745 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 83.20%\n",
      "Epoch 2/3 [11710/11711] 100.0% | Loss: 0.5754 | Accuracy: 83.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 17:31:50,107 - INFO - Epoch 2 completed. Validation accuracy: 84.08%\n",
      "2024-11-17 17:31:52,150 - INFO - Model saved to checkpoint_epoch_2.pt\n",
      "2024-11-17 17:31:52,154 - INFO - Checkpoint saved: checkpoint_epoch_2.pt\n",
      "2024-11-17 17:31:52,156 - INFO - \n",
      "Starting Epoch 3/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 [100/11711] 0.9% | Loss: 0.4983 | Accuracy: 84.62%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 17:36:12,901 - INFO - Model saved to best_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best model saved with accuracy: 84.65%\n",
      "Epoch 3/3 [11710/11711] 100.0% | Loss: 0.5382 | Accuracy: 83.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 04:28:19,135 - INFO - Epoch 3 completed. Validation accuracy: 84.71%\n",
      "2024-11-18 04:28:19,899 - INFO - Model saved to checkpoint_epoch_3.pt\n",
      "2024-11-18 04:28:19,901 - INFO - Checkpoint saved: checkpoint_epoch_3.pt\n",
      "2024-11-18 04:28:20,510 - INFO - Model saved to final_model.pt\n",
      "2024-11-18 04:28:20,511 - INFO - Final model saved\n",
      "2024-11-18 04:28:21,126 - INFO - Model saved to models\\cybercrime_classifier\\final_model.pt\n",
      "2024-11-18 04:28:21,128 - INFO - Evaluating model...\n",
      "2024-11-18 04:28:21,131 - INFO - Evaluating model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Progress: 99.9% [3900/3904] | Loss: 0.5378"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 05:14:54,233 - INFO - Evaluation results saved to models\\cybercrime_classifier\\evaluation_results.pt\n",
      "2024-11-18 05:14:54,235 - INFO - \n",
      "Testing model with sample prediction...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Diagnostics:\n",
      "Number of unique classes in predictions: 10\n",
      "Number of unique classes in true labels: 14\n",
      "Number of classes in label encoder: 15\n",
      "\n",
      "Class distribution in predictions:\n",
      "Class 0 (Any Other Cyber Crime): 628 samples (2.01%)\n",
      "Class 1 (Child Pornography CPChild Sexual Abuse Material CSAM): 61 samples (0.20%)\n",
      "Class 2 (Cryptocurrency Crime): 128 samples (0.41%)\n",
      "Class 3 (Cyber Attack/ Dependent Crimes): 1265 samples (4.05%)\n",
      "Class 5 (Hacking  Damage to computercomputer system etc): 507 samples (1.62%)\n",
      "Class 7 (Online Financial Fraud): 23428 samples (75.02%)\n",
      "Class 8 (Online Gambling  Betting): 1 samples (0.00%)\n",
      "Class 9 (Online and Social Media Related Crime): 4127 samples (13.22%)\n",
      "Class 11 (RapeGang Rape RGRSexually Abusive Content): 825 samples (2.64%)\n",
      "Class 14 (Sexually Obscene material): 259 samples (0.83%)\n",
      "\n",
      "Class distribution in true labels:\n",
      "Class 0 (Any Other Cyber Crime): 710 samples (2.27%)\n",
      "Class 1 (Child Pornography CPChild Sexual Abuse Material CSAM): 123 samples (0.39%)\n",
      "Class 2 (Cryptocurrency Crime): 167 samples (0.53%)\n",
      "Class 3 (Cyber Attack/ Dependent Crimes): 1303 samples (4.17%)\n",
      "Class 4 (Cyber Terrorism): 52 samples (0.17%)\n",
      "Class 5 (Hacking  Damage to computercomputer system etc): 592 samples (1.90%)\n",
      "Class 6 (Online Cyber Trafficking): 61 samples (0.20%)\n",
      "Class 7 (Online Financial Fraud): 21620 samples (69.23%)\n",
      "Class 8 (Online Gambling  Betting): 134 samples (0.43%)\n",
      "Class 9 (Online and Social Media Related Crime): 4336 samples (13.88%)\n",
      "Class 10 (Ransomware): 18 samples (0.06%)\n",
      "Class 11 (RapeGang Rape RGRSexually Abusive Content): 912 samples (2.92%)\n",
      "Class 13 (Sexually Explicit Act): 535 samples (1.71%)\n",
      "Class 14 (Sexually Obscene material): 666 samples (2.13%)\n",
      "\n",
      "Classification Report:\n",
      "                                                      precision    recall  f1-score   support\n",
      "\n",
      "                               Any Other Cyber Crime     0.4570    0.4042    0.4290       710\n",
      "Child Pornography CPChild Sexual Abuse Material CSAM     0.5574    0.2764    0.3696       123\n",
      "                                Cryptocurrency Crime     0.5312    0.4072    0.4610       167\n",
      "                      Cyber Attack/ Dependent Crimes     1.0000    0.9708    0.9852      1303\n",
      "      Hacking  Damage to computercomputer system etc     0.3215    0.2753    0.2966       592\n",
      "                              Online Financial Fraud     0.8893    0.9636    0.9250     21620\n",
      "                            Online Gambling  Betting     0.0000    0.0000    0.0000       134\n",
      "               Online and Social Media Related Crime     0.6191    0.5893    0.6038      4336\n",
      "           RapeGang Rape RGRSexually Abusive Content     1.0000    0.9046    0.9499       912\n",
      "                           Sexually Obscene material     0.3745    0.1456    0.2097       666\n",
      "\n",
      "                                           micro avg     0.8367    0.8549    0.8457     30563\n",
      "                                           macro avg     0.5750    0.4937    0.5230     30563\n",
      "                                        weighted avg     0.8195    0.8549    0.8346     30563\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "Labels: ['Any Other Cyber Crime', 'Child Pornography CPChild Sexual Abuse Material CSAM', 'Cryptocurrency Crime', 'Cyber Attack/ Dependent Crimes', 'Hacking  Damage to computercomputer system etc', 'Online Financial Fraud', 'Online Gambling  Betting', 'Online and Social Media Related Crime', 'RapeGang Rape RGRSexually Abusive Content', 'Sexually Obscene material']\n",
      "\n",
      "Matrix:\n",
      "Any Other Cyber Crim:   287     1     2     0     9   316     0    87     0     8\n",
      "Child Pornography CP:     2    34     0     0     0    26     0    43     0    18\n",
      "Cryptocurrency Crime:     0     0    68     0     3    93     0     3     0     0\n",
      "Cyber Attack/ Depend:     0     0     0  1265    27     5     0     6     0     0\n",
      "Hacking  Damage to c:    22     0     1     0   163   278     0   126     0     2\n",
      "Online Financial Fra:   152     0    48     0   115 20834     1   467     0     3\n",
      "Online Gambling  Bet:     4     0     1     0     0   115     0    14     0     0\n",
      "Online and Social Me:   118     3     7     0   147  1445     0  2555     0    61\n",
      "RapeGang Rape RGRSex:     2     1     0     0     1    19     0    46   825    18\n",
      "Sexually Obscene mat:    17    14     0     0    12    94     0   432     0    97\n",
      "\n",
      "Overall Metrics:\n",
      "Accuracy: 83.67%\n",
      "\n",
      "Per-class Accuracy:\n",
      "Any Other Cyber Crime: 40.42%\n",
      "Child Pornography CPChild Sexual Abuse Material CSAM: 27.64%\n",
      "Cryptocurrency Crime: 40.72%\n",
      "Cyber Attack/ Dependent Crimes: 97.08%\n",
      "Hacking  Damage to computercomputer system etc: 0.00%\n",
      "Online Financial Fraud: 27.53%\n",
      "Online Gambling  Betting: 0.00%\n",
      "Online and Social Media Related Crime: 96.36%\n",
      "RapeGang Rape RGRSexually Abusive Content: 0.00%\n",
      "Sexually Obscene material: 58.93%\n",
      "\n",
      "Sample Prediction:\n",
      "Text: I received a call from someone claiming to be from SBI bank asking for my card details. \n",
      "        The...\n",
      "Predicted Category: Online Financial Fraud\n",
      "Confidence: 99.01%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm.auto import tqdm\n",
    "import logging\n",
    "import warnings\n",
    "from typing import Dict, List, Tuple, Union, Optional\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import traceback\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        # Data paths\n",
    "        self.train_path = 'cleaned_cybercrime_data.csv'\n",
    "        self.test_path = 'cleaned_cybercrime_test_data.csv'\n",
    "        \n",
    "        # High-accuracy model parameters\n",
    "        self.model_name = 'roberta-base'  # Changed from DeBERTa\n",
    "        self.max_length = 512     # Increased from 256\n",
    "        self.batch_size = 8       \n",
    "        self.num_epochs = 3       # Increased from 3\n",
    "        self.learning_rate = 2e-5 # Adjusted for RoBERTa\n",
    "        self.warmup_ratio = 0.1\n",
    "        self.weight_decay = 0.01\n",
    "        \n",
    "        # Training optimizations\n",
    "        self.gradient_accumulation_steps = 4\n",
    "        self.eval_steps = 100     # More frequent evaluation\n",
    "        self.save_steps = 100\n",
    "        self.max_grad_norm = 1.0  # Added gradient clipping\n",
    "        \n",
    "        # Device settings\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        # Parallel processing settings\n",
    "        self.num_workers = 4 if self.device == 'cuda' else 2\n",
    "        self.pin_memory = True if self.device == 'cuda' else False\n",
    "        \n",
    "        # Text preprocessing\n",
    "        self.max_vocab_size = 50000\n",
    "        self.text_column = 'crimeaditionalinfo'\n",
    "        self.label_column = 'category'\n",
    "        \n",
    "        # Output directory\n",
    "        self.output_dir = Path('models/cybercrime_classifier')\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "class TextPreprocessor:\n",
    "    \"\"\"Efficient text preprocessing for CPU\"\"\"\n",
    "    def __init__(self):\n",
    "        self.patterns = {\n",
    "            'url': re.compile(r'https?://\\S+|www\\.\\S+'),\n",
    "            'email': re.compile(r'\\S+@\\S+'),\n",
    "            'phone': re.compile(r'(\\+\\d{1,3}[-.]?)?\\d{3}[-.]?\\d{3}[-.]?\\d{4}'),\n",
    "            'amount': re.compile(r'(?:rs\\.?|inr|₹|\\$)\\s*\\d+(?:[,\\.]\\d+)*'),\n",
    "            'special_chars': re.compile(r'[^\\w\\s]'),\n",
    "            'extra_spaces': re.compile(r'\\s+')\n",
    "        }\n",
    "        \n",
    "        self.cache = {}\n",
    "        \n",
    "    def clean_text(self, text: str) -> str:\n",
    "        \"\"\"Clean text with caching for efficiency\"\"\"\n",
    "        if text in self.cache:\n",
    "            return self.cache[text]\n",
    "            \n",
    "        text = text.lower().strip()\n",
    "        \n",
    "        # Replace patterns with tokens\n",
    "        text = self.patterns['url'].sub('[URL]', text)\n",
    "        text = self.patterns['email'].sub('[EMAIL]', text)\n",
    "        text = self.patterns['phone'].sub('[PHONE]', text)\n",
    "        text = self.patterns['amount'].sub('[AMOUNT]', text)\n",
    "        \n",
    "        # Remove special characters and extra spaces\n",
    "        text = self.patterns['special_chars'].sub(' ', text)\n",
    "        text = self.patterns['extra_spaces'].sub(' ', text).strip()\n",
    "        \n",
    "        # Cache result\n",
    "        if len(self.cache) > 10000:  # Limit cache size\n",
    "            self.cache.clear()\n",
    "        self.cache[text] = text\n",
    "        \n",
    "        return text\n",
    "\n",
    "    def batch_process(self, texts: List[str], batch_size: int = 1000) -> List[str]:\n",
    "        \"\"\"Process texts in batches\"\"\"\n",
    "        processed_texts = []\n",
    "        \n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i + batch_size]\n",
    "            processed_batch = [self.clean_text(text) for text in batch]\n",
    "            processed_texts.extend(processed_batch)\n",
    "            \n",
    "        return processed_texts\n",
    "        \n",
    "        \n",
    "class SmartLabelEncoder:\n",
    "    \"\"\"Enhanced label encoder that handles unseen labels using semantic similarity\"\"\"\n",
    "    def __init__(self):\n",
    "        self.encoder = LabelEncoder()\n",
    "        self.sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        self.label_embeddings = None\n",
    "        self.original_labels = None\n",
    "        self.mapping = {}\n",
    "        self.label_vectors = None\n",
    "\n",
    "    def fit(self, labels: List[str], texts: List[str]) -> 'SmartLabelEncoder':\n",
    "        \"\"\"Fit encoder and compute label embeddings\"\"\"\n",
    "        self.original_labels = list(set(labels))\n",
    "        self.encoder.fit(self.original_labels)\n",
    "        \n",
    "        # Create mapping of labels to their texts\n",
    "        label_texts = {}\n",
    "        for label, text in zip(labels, texts):\n",
    "            if label not in label_texts:\n",
    "                label_texts[label] = []\n",
    "            label_texts[label].append(text)\n",
    "        \n",
    "        # Create embeddings for each label's texts\n",
    "        self.label_vectors = {}\n",
    "        for label, texts in label_texts.items():\n",
    "            # Get text embeddings\n",
    "            text_embeddings = self.sentence_model.encode(texts[:5])  # Use up to 5 examples\n",
    "            # Calculate centroid\n",
    "            self.label_vectors[label] = np.mean(text_embeddings, axis=0)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _create_label_descriptions(self, labels: List[str], texts: List[str]) -> Dict[str, str]:\n",
    "        \"\"\"Create rich descriptions for each label based on its examples\"\"\"\n",
    "        descriptions = {}\n",
    "        for label, text in zip(labels, texts):\n",
    "            if label not in descriptions:\n",
    "                descriptions[label] = []\n",
    "            descriptions[label].append(text)\n",
    "        \n",
    "        # Combine examples for each label\n",
    "        for label in descriptions:\n",
    "            examples = descriptions[label][:5]  # Take up to 5 examples\n",
    "            descriptions[label] = f\"{label}: \" + \" \".join(examples)\n",
    "            \n",
    "        return descriptions\n",
    "    \n",
    "    def _create_label_vectors(self, descriptions: Dict[str, str]) -> Dict[str, Dict[str, np.ndarray]]:\n",
    "        \"\"\"Create enhanced vector representations of labels\"\"\"\n",
    "        vectors = {}\n",
    "        for label, texts in descriptions.items():\n",
    "            # Create embeddings for all texts\n",
    "            text_embeddings = self.sentence_model.encode(texts)\n",
    "            text_centroid = np.mean(text_embeddings, axis=0)\n",
    "            \n",
    "            vectors[label] = {\n",
    "                'text_embeddings': text_embeddings,\n",
    "                'text_centroid': text_centroid,\n",
    "            }\n",
    "        return vectors\n",
    "\n",
    "    \n",
    "    def _find_most_similar_label(self, unknown_label: str, texts: List[str]) -> str:\n",
    "        \"\"\"Find most similar known label using semantic similarity\"\"\"\n",
    "        # Create embedding for unknown label's texts\n",
    "        unknown_embeddings = self.sentence_model.encode(texts[:5])  # Use up to 5 examples\n",
    "        unknown_centroid = np.mean(unknown_embeddings, axis=0)\n",
    "        \n",
    "        # Calculate similarities\n",
    "        similarities = {}\n",
    "        for known_label, known_embedding in self.label_vectors.items():\n",
    "            # Calculate cosine similarity\n",
    "            similarity = cosine_similarity(\n",
    "                unknown_centroid.reshape(1, -1),\n",
    "                known_embedding.reshape(1, -1)\n",
    "            )[0][0]\n",
    "            \n",
    "            similarities[known_label] = similarity\n",
    "            logger.info(f\"Similarity between '{unknown_label}' and '{known_label}': {similarity:.4f}\")\n",
    "        \n",
    "        # Get most similar label\n",
    "        most_similar = max(similarities.items(), key=lambda x: x[1])\n",
    "        logger.info(\n",
    "            f\"Mapping unknown label '{unknown_label}' to '{most_similar[0]}' \"\n",
    "            f\"with similarity {most_similar[1]:.4f}\"\n",
    "        )\n",
    "        return most_similar[0]\n",
    "    \n",
    "    def transform(self, labels: List[str], texts: List[str] = None) -> np.ndarray:\n",
    "        \"\"\"Transform labels, mapping unseen ones to most similar known labels\"\"\"\n",
    "        processed_labels = []\n",
    "        for i, label in enumerate(labels):\n",
    "            if label not in self.original_labels:\n",
    "                if label not in self.mapping:\n",
    "                    # Get relevant texts for this label\n",
    "                    label_texts = [text for l, text in zip(labels, texts) if l == label]\n",
    "                    if not label_texts:  # If no texts found, use empty list\n",
    "                        label_texts = ['']\n",
    "                    self.mapping[label] = self._find_most_similar_label(label, label_texts)\n",
    "                processed_labels.append(self.mapping[label])\n",
    "            else:\n",
    "                processed_labels.append(label)\n",
    "        \n",
    "        return self.encoder.transform(processed_labels)\n",
    "    \n",
    "    def inverse_transform(self, indices: np.ndarray) -> np.ndarray:\n",
    "        return self.encoder.inverse_transform(indices)\n",
    "    \n",
    "    @property\n",
    "    def classes_(self) -> np.ndarray:\n",
    "        return self.encoder.classes_\n",
    "\n",
    "class CybercrimeDataset(Dataset):\n",
    "    \"\"\"Custom dataset for cybercrime text classification\"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        texts: List[str],\n",
    "        labels: List[int] = None,\n",
    "        tokenizer = None,\n",
    "        max_length: int = 128\n",
    "    ):\n",
    "        # Convert texts to list and handle NaN values\n",
    "        self.texts = [str(text) for text in texts]\n",
    "        \n",
    "        # Pre-tokenize all texts at once\n",
    "        self.encodings = tokenizer(\n",
    "            self.texts,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Convert labels to Long tensor if provided\n",
    "        if labels is not None:\n",
    "            self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "        else:\n",
    "            self.labels = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            'input_ids': self.encodings['input_ids'][idx],\n",
    "            'attention_mask': self.encodings['attention_mask'][idx],\n",
    "        }\n",
    "        \n",
    "        if self.labels is not None:\n",
    "            item['labels'] = self.labels[idx]\n",
    "            \n",
    "        return item\n",
    "\n",
    "class CybercrimeClassifier:\n",
    "    \"\"\"Main classifier class with enhanced training and evaluation\"\"\"\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.device = config.device\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "        self.model = None\n",
    "        self.label_encoder = SmartLabelEncoder()\n",
    "        \n",
    "    def prepare_data(self) -> Tuple[DataLoader, DataLoader]:\n",
    "        \"\"\"Load and prepare train and test data\"\"\"\n",
    "        logger.info(\"Loading datasets...\")\n",
    "        \n",
    "        # Load data\n",
    "        train_df = pd.read_csv(self.config.train_path)\n",
    "        test_df = pd.read_csv(self.config.test_path)\n",
    "        \n",
    "        # Convert text columns to string and fill NaN values\n",
    "        train_df[self.config.text_column] = train_df[self.config.text_column].fillna('').astype(str)\n",
    "        test_df[self.config.text_column] = test_df[self.config.text_column].fillna('').astype(str)\n",
    "        \n",
    "        # Log dataset statistics\n",
    "        logger.info(f\"Training set size: {len(train_df)}\")\n",
    "        logger.info(f\"Test set size: {len(test_df)}\")\n",
    "        logger.info(\"\\nTraining set label distribution:\")\n",
    "        for label, count in train_df[self.config.label_column].value_counts().items():\n",
    "            logger.info(f\"{label}: {count}\")\n",
    "        \n",
    "        # Check for unseen labels\n",
    "        train_labels = set(train_df[self.config.label_column].unique())\n",
    "        test_labels = set(test_df[self.config.label_column].unique())\n",
    "        unseen_labels = test_labels - train_labels\n",
    "        if unseen_labels:\n",
    "            logger.warning(f\"Found {len(unseen_labels)} unseen labels in test set: {unseen_labels}\")\n",
    "        \n",
    "        # Encode labels using smart encoder\n",
    "        self.label_encoder.fit(\n",
    "            train_df[self.config.label_column].tolist(),\n",
    "            train_df[self.config.text_column].tolist()\n",
    "        )\n",
    "        \n",
    "        train_labels = self.label_encoder.transform(\n",
    "            train_df[self.config.label_column].tolist(),\n",
    "            train_df[self.config.text_column].tolist()\n",
    "        ).astype(np.int64)\n",
    "        \n",
    "        test_labels = self.label_encoder.transform(\n",
    "            test_df[self.config.label_column].tolist(),\n",
    "            test_df[self.config.text_column].tolist()\n",
    "        ).astype(np.int64)\n",
    "        \n",
    "        num_labels = len(self.label_encoder.classes_)\n",
    "        logger.info(f\"Number of unique labels: {num_labels}\")\n",
    "        \n",
    "        # Initialize model\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            self.config.model_name,\n",
    "            num_labels=num_labels,\n",
    "            problem_type=\"single_label_classification\"\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Create datasets\n",
    "        train_dataset = CybercrimeDataset(\n",
    "            texts=train_df[self.config.text_column].tolist(),\n",
    "            labels=train_labels,\n",
    "            tokenizer=self.tokenizer,\n",
    "            max_length=self.config.max_length\n",
    "        )\n",
    "        \n",
    "        test_dataset = CybercrimeDataset(\n",
    "            texts=test_df[self.config.text_column].tolist(),\n",
    "            labels=test_labels,\n",
    "            tokenizer=self.tokenizer,\n",
    "            max_length=self.config.max_length\n",
    "        )\n",
    "        \n",
    "        # Create dataloaders\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.config.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=0,\n",
    "            pin_memory=False\n",
    "        )\n",
    "        \n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=self.config.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=0,\n",
    "            pin_memory=False\n",
    "        )\n",
    "        \n",
    "        return train_loader, test_loader\n",
    "        \n",
    "    def train(self, train_loader: DataLoader) -> None:\n",
    "        \"\"\"Balanced training loop for speed and accuracy\"\"\"\n",
    "        try:\n",
    "            logger.info(\"Starting training...\")\n",
    "    \n",
    "            optimizer = torch.optim.AdamW(\n",
    "                self.model.parameters(),\n",
    "                lr=self.config.learning_rate,\n",
    "                weight_decay=self.config.weight_decay,\n",
    "                betas=(0.9, 0.999)\n",
    "            )\n",
    "    \n",
    "            total_steps = len(train_loader) * self.config.num_epochs\n",
    "            scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "                optimizer,\n",
    "                max_lr=self.config.learning_rate,\n",
    "                total_steps=total_steps,\n",
    "                pct_start=0.1\n",
    "            )\n",
    "    \n",
    "            best_loss = float('inf')\n",
    "            best_accuracy = 0.0\n",
    "    \n",
    "            for epoch in range(self.config.num_epochs):\n",
    "                logger.info(f\"\\nStarting Epoch {epoch + 1}/{self.config.num_epochs}\")\n",
    "                self.model.train()\n",
    "                running_loss = 0\n",
    "                running_correct = 0\n",
    "                running_total = 0\n",
    "                \n",
    "                total_batches = len(train_loader)\n",
    "    \n",
    "                try:\n",
    "                    for batch_idx, batch in enumerate(train_loader):\n",
    "                        # Zero gradients\n",
    "                        optimizer.zero_grad()\n",
    "    \n",
    "                        # Move batch to device\n",
    "                        batch = {k: v.to(self.device, non_blocking=True) for k, v in batch.items()}\n",
    "    \n",
    "                        # Forward pass\n",
    "                        outputs = self.model(**batch)\n",
    "                        loss = outputs.loss / self.config.gradient_accumulation_steps\n",
    "    \n",
    "                        # Backward pass\n",
    "                        loss.backward()\n",
    "    \n",
    "                        # Gradient accumulation\n",
    "                        if (batch_idx + 1) % self.config.gradient_accumulation_steps == 0:\n",
    "                            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "                            optimizer.step()\n",
    "                            scheduler.step()\n",
    "                            optimizer.zero_grad()\n",
    "    \n",
    "                        # Calculate accuracy\n",
    "                        with torch.no_grad():\n",
    "                            predictions = outputs.logits.argmax(-1)\n",
    "                            correct = (predictions == batch['labels']).sum().item()\n",
    "                            total = batch['labels'].size(0)\n",
    "                            running_correct += correct\n",
    "                            running_total += total\n",
    "    \n",
    "                        running_loss += loss.item() * self.config.gradient_accumulation_steps\n",
    "    \n",
    "                        # Print progress every 10 batches\n",
    "                        if (batch_idx + 1) % 10 == 0:\n",
    "                            avg_loss = running_loss / (batch_idx + 1)\n",
    "                            accuracy = (running_correct / running_total) * 100\n",
    "                            progress = (batch_idx + 1) / total_batches * 100\n",
    "                            \n",
    "                            print(f\"\\rEpoch {epoch + 1}/{self.config.num_epochs} \"\n",
    "                                  f\"[{batch_idx + 1}/{total_batches}] \"\n",
    "                                  f\"{progress:.1f}% | \"\n",
    "                                  f\"Loss: {avg_loss:.4f} | \"\n",
    "                                  f\"Accuracy: {accuracy:.2f}%\", end=\"\")\n",
    "    \n",
    "                        # Save best model\n",
    "                        if batch_idx > 0 and batch_idx % self.config.eval_steps == 0:\n",
    "                            current_accuracy = (running_correct / running_total) * 100\n",
    "                            if current_accuracy > best_accuracy:\n",
    "                                best_accuracy = current_accuracy\n",
    "                                self.save_model('best_model.pt')\n",
    "                                print(f\"\\nNew best model saved with accuracy: {best_accuracy:.2f}%\")\n",
    "    \n",
    "                    # Print newline at epoch end\n",
    "                    print()\n",
    "    \n",
    "                    # Epoch end validation\n",
    "                    val_accuracy = self.quick_evaluate(train_loader)\n",
    "                    logger.info(f\"Epoch {epoch + 1} completed. Validation accuracy: {val_accuracy:.2f}%\")\n",
    "    \n",
    "                    # Save checkpoint\n",
    "                    checkpoint_path = f'checkpoint_epoch_{epoch+1}.pt'\n",
    "                    self.save_model(checkpoint_path)\n",
    "                    logger.info(f\"Checkpoint saved: {checkpoint_path}\")\n",
    "    \n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error during epoch {epoch + 1}: {str(e)}\")\n",
    "                    logger.error(traceback.format_exc())\n",
    "                    self.save_model(f'emergency_checkpoint_epoch_{epoch+1}.pt')\n",
    "                    raise\n",
    "    \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Training error: {str(e)}\")\n",
    "            logger.error(traceback.format_exc())\n",
    "            raise\n",
    "        finally:\n",
    "            try:\n",
    "                self.save_model('final_model.pt')\n",
    "                logger.info(\"Final model saved\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error saving final model: {str(e)}\")\n",
    "\n",
    "    def quick_evaluate(self, loader: DataLoader) -> float:\n",
    "        \"\"\"Quick evaluation during training\"\"\"\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        self.model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in loader:\n",
    "                batch = {k: v.to(self.device, non_blocking=True) for k, v in batch.items()}\n",
    "                outputs = self.model(**batch)\n",
    "                predictions = outputs.logits.argmax(-1)\n",
    "                correct += (predictions == batch['labels']).sum().item()\n",
    "                total += batch['labels'].size(0)\n",
    "\n",
    "        return (correct / total) * 100\n",
    "\n",
    "\n",
    "                \n",
    "    def evaluate(self, test_loader: DataLoader) -> None:\n",
    "        \"\"\"Evaluate the model on test data with improved error handling\"\"\"\n",
    "        logger.info(\"Evaluating model...\")\n",
    "        \n",
    "        self.model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        running_loss = 0\n",
    "        \n",
    "        # Collect predictions\n",
    "        total_batches = len(test_loader)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(test_loader):\n",
    "                # Move batch to device\n",
    "                batch = {k: v.to(self.device) for k, v in batch.items()}\n",
    "                \n",
    "                # Get model outputs\n",
    "                outputs = self.model(**batch)\n",
    "                loss = outputs.loss\n",
    "                preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "                \n",
    "                # Store predictions and labels\n",
    "                all_preds.extend(preds)\n",
    "                all_labels.extend(batch['labels'].cpu().numpy())\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                # Print progress\n",
    "                if (batch_idx + 1) % 10 == 0:\n",
    "                    progress = (batch_idx + 1) / total_batches * 100\n",
    "                    avg_loss = running_loss / (batch_idx + 1)\n",
    "                    print(f\"\\rEvaluation Progress: {progress:.1f}% [{batch_idx + 1}/{total_batches}] | \"\n",
    "                          f\"Loss: {avg_loss:.4f}\", end=\"\")\n",
    "        \n",
    "        print()  # New line after progress\n",
    "        \n",
    "        # Convert to numpy arrays\n",
    "        all_preds = np.array(all_preds)\n",
    "        all_labels = np.array(all_labels)\n",
    "        \n",
    "        # Get unique classes in predictions and true labels\n",
    "        unique_preds = np.unique(all_preds)\n",
    "        unique_labels = np.unique(all_labels)\n",
    "        \n",
    "        # Print diagnostics\n",
    "        print(\"\\nDiagnostics:\")\n",
    "        print(f\"Number of unique classes in predictions: {len(unique_preds)}\")\n",
    "        print(f\"Number of unique classes in true labels: {len(unique_labels)}\")\n",
    "        print(f\"Number of classes in label encoder: {len(self.label_encoder.classes_)}\")\n",
    "        \n",
    "        print(\"\\nClass distribution in predictions:\")\n",
    "        pred_counts = Counter(all_preds)\n",
    "        for class_idx, count in sorted(pred_counts.items()):\n",
    "            class_name = self.label_encoder.inverse_transform([class_idx])[0]\n",
    "            percentage = (count / len(all_preds)) * 100\n",
    "            print(f\"Class {class_idx} ({class_name}): {count} samples ({percentage:.2f}%)\")\n",
    "        \n",
    "        print(\"\\nClass distribution in true labels:\")\n",
    "        label_counts = Counter(all_labels)\n",
    "        for class_idx, count in sorted(label_counts.items()):\n",
    "            class_name = self.label_encoder.inverse_transform([class_idx])[0]\n",
    "            percentage = (count / len(all_labels)) * 100\n",
    "            print(f\"Class {class_idx} ({class_name}): {count} samples ({percentage:.2f}%)\")\n",
    "        \n",
    "        # Get the intersection of classes present in both predictions and true labels\n",
    "        present_classes = sorted(set(unique_preds) & set(unique_labels))\n",
    "        class_names = self.label_encoder.inverse_transform(present_classes)\n",
    "        \n",
    "        # Print classification report with only present classes\n",
    "        print(\"\\nClassification Report:\")\n",
    "        try:\n",
    "            # Generate and print detailed classification report\n",
    "            report = classification_report(\n",
    "                all_labels,\n",
    "                all_preds,\n",
    "                labels=present_classes,\n",
    "                target_names=class_names,\n",
    "                digits=4,\n",
    "                zero_division=0\n",
    "            )\n",
    "            print(report)\n",
    "            \n",
    "            # Print confusion matrix with better formatting\n",
    "            cm = confusion_matrix(all_labels, all_preds, labels=present_classes)\n",
    "            print(\"\\nConfusion Matrix:\")\n",
    "            print(\"Labels:\", class_names.tolist())\n",
    "            \n",
    "            # Print matrix with proper alignment\n",
    "            print(\"\\nMatrix:\")\n",
    "            max_value_width = max(len(str(x)) for x in cm.flatten())\n",
    "            format_str = f'{{:{max_value_width}d}}'\n",
    "            \n",
    "            for i, row in enumerate(cm):\n",
    "                formatted_row = [format_str.format(x) for x in row]\n",
    "                print(f\"{class_names[i][:20]:20s}: {' '.join(formatted_row)}\")\n",
    "            \n",
    "            # Calculate and print additional metrics\n",
    "            accuracy = (all_preds == all_labels).mean() * 100\n",
    "            print(f\"\\nOverall Metrics:\")\n",
    "            print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "            \n",
    "            # Calculate per-class accuracy\n",
    "            print(\"\\nPer-class Accuracy:\")\n",
    "            for i, class_name in enumerate(class_names):\n",
    "                class_mask = (all_labels == i)\n",
    "                if class_mask.sum() > 0:\n",
    "                    class_accuracy = (all_preds[class_mask] == all_labels[class_mask]).mean() * 100\n",
    "                    print(f\"{class_name}: {class_accuracy:.2f}%\")\n",
    "            \n",
    "            # Save evaluation results\n",
    "            try:\n",
    "                eval_results = {\n",
    "                    'accuracy': accuracy,\n",
    "                    'classification_report': report,\n",
    "                    'confusion_matrix': cm.tolist(),\n",
    "                    'class_names': class_names.tolist(),\n",
    "                    'timestamp': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                }\n",
    "                \n",
    "                eval_path = self.config.output_dir / 'evaluation_results.pt'\n",
    "                torch.save(eval_results, eval_path)\n",
    "                logger.info(f\"Evaluation results saved to {eval_path}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error saving evaluation results: {str(e)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in generating classification report: {str(e)}\")\n",
    "            logger.error(traceback.format_exc())\n",
    "            \n",
    "            # Print basic accuracy even if detailed metrics fail\n",
    "            accuracy = (all_preds == all_labels).mean() * 100\n",
    "            print(f\"\\nBasic Accuracy: {accuracy:.2f}%\")\n",
    "        \n",
    "    # Update the CybercrimeClassifier class with the new evaluate method\n",
    "    \n",
    "        \n",
    "    def predict(self, text: str) -> Tuple[str, float]:\n",
    "        \"\"\"Predict category for a single text\"\"\"\n",
    "        self.model.eval()\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.config.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        encoding = {k: v.to(self.device) for k, v in encoding.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**encoding)\n",
    "            probs = F.softmax(outputs.logits, dim=1)\n",
    "            predicted_class = torch.argmax(probs, dim=1).cpu().numpy()[0]\n",
    "            confidence = probs[0][predicted_class].cpu().numpy()\n",
    "        \n",
    "        predicted_category = self.label_encoder.inverse_transform([predicted_class])[0]\n",
    "        return predicted_category, confidence\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def save_model(self, path: str) -> None:\n",
    "        \"\"\"Save model and label encoder\"\"\"\n",
    "        save_dict = {\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'label_encoder': self.label_encoder,\n",
    "            'config': self.config,\n",
    "        }\n",
    "        torch.save(save_dict, path)\n",
    "        logger.info(f\"Model saved to {path}\")\n",
    "\n",
    "    def load_model(self, path: str) -> None:\n",
    "        \"\"\"Load model and label encoder\"\"\"\n",
    "        save_dict = torch.load(path, map_location=self.device)\n",
    "        self.model.load_state_dict(save_dict['model_state_dict'])\n",
    "        self.label_encoder = save_dict['label_encoder']\n",
    "        logger.info(f\"Model loaded from {path}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    try:\n",
    "        # Initialize configuration\n",
    "        config = Config()\n",
    "        logger.info(f\"Using device: {config.device}\")\n",
    "        \n",
    "        # Initialize classifier\n",
    "        classifier = CybercrimeClassifier(config)\n",
    "        \n",
    "        # Prepare data\n",
    "        logger.info(\"Preparing data...\")\n",
    "        train_loader, test_loader = classifier.prepare_data()\n",
    "        \n",
    "        # Train model\n",
    "        logger.info(\"Starting training process...\")\n",
    "        classifier.train(train_loader)\n",
    "        \n",
    "        # Save final model\n",
    "        classifier.save_model(config.output_dir / 'final_model.pt')\n",
    "        \n",
    "        # Evaluate model\n",
    "        logger.info(\"Evaluating model...\")\n",
    "        classifier.evaluate(test_loader)\n",
    "        \n",
    "        # Example prediction\n",
    "        sample_text = \"\"\"I received a call from someone claiming to be from SBI bank asking for my card details. \n",
    "        They said my card would be blocked. I gave them my details and lost Rs. 50,000.\"\"\"\n",
    "        \n",
    "        logger.info(\"\\nTesting model with sample prediction...\")\n",
    "        predicted_category, confidence = classifier.predict(sample_text)\n",
    "        print(f\"\\nSample Prediction:\")\n",
    "        print(f\"Text: {sample_text[:100]}...\")\n",
    "        print(f\"Predicted Category: {predicted_category}\")\n",
    "        print(f\"Confidence: {confidence:.2%}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred: {str(e)}\")\n",
    "        logger.error(f\"Stack trace: {traceback.format_exc()}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set random seeds for reproducibility\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(42)\n",
    "    \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8bbb63-f94f-4f4c-8b5f-2b980ff4a647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe30289-e2d7-4f6d-b7fc-1eab037f4ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d291ef7f-d921-44bd-9fd7-2339ff8e2bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a99a1b3-7279-4fa1-9a46-f19d94a3fc0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b003b807-c6b4-4c3c-bb0b-20d3200c5ffb",
   "metadata": {},
   "source": [
    "# Running the file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81edfefd-9a8b-4f5d-853b-1a616531116e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e197e5e0-c479-45ad-ba02-e63faf1ecaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 11:40:14,626 - INFO - Using device: cuda\n",
      "2024-11-19 11:40:14,631 - INFO - Loading model from final_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Cybercrime Classification System...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kollm\\AppData\\Local\\Temp\\ipykernel_5000\\1443517030.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  saved_data = torch.load(model_path, map_location=self.device)\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2024-11-19 11:40:18,074 - INFO - Model loaded successfully!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cybercrime Classification Menu:\n",
      "1. Test with custom input\n",
      "2. Test with examples from test dataset\n",
      "3. Exit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your choice (1-3):  2\n",
      "\n",
      "How many random examples to test? (press Enter for all):  10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing 10 examples from cleaned_cybercrime_test_data.csv\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "371188ea3cc54ebc925589c7d5eadaa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing examples:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Overall Statistics ===\n",
      "Total Examples: 10\n",
      "Correct Predictions: 7\n",
      "Wrong Predictions: 3\n",
      "Overall Accuracy: 70.00%\n",
      "\n",
      "=== Category-wise Statistics ===\n",
      "\n",
      "Online Financial Fraud (7 cases):\n",
      "├── Correct: 6\n",
      "├── Wrong: 1\n",
      "├── Accuracy: 85.71%\n",
      "└── Avg Confidence: 0.87%\n",
      "\n",
      "Online and Social Media Related Crime (1 cases):\n",
      "├── Correct: 0\n",
      "├── Wrong: 1\n",
      "├── Accuracy: 0.00%\n",
      "└── Avg Confidence: 0.84%\n",
      "\n",
      "Cyber Attack/ Dependent Crimes (1 cases):\n",
      "├── Correct: 1\n",
      "├── Wrong: 0\n",
      "├── Accuracy: 100.00%\n",
      "└── Avg Confidence: 1.00%\n",
      "\n",
      "Sexually Explicit Act (1 cases):\n",
      "├── Correct: 0\n",
      "├── Wrong: 1\n",
      "├── Accuracy: 0.00%\n",
      "└── Avg Confidence: 0.75%\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "\n",
      "True Category: Online Financial Fraud\n",
      "├── Predicted as Online Financial Fraud: 6 (85.7%)\n",
      "├── Predicted as Online and Social Media Related Crime: 1 (14.3%)\n",
      "\n",
      "True Category: Online and Social Media Related Crime\n",
      "├── Predicted as Online Financial Fraud: 1 (100.0%)\n",
      "\n",
      "True Category: Cyber Attack/ Dependent Crimes\n",
      "├── Predicted as Cyber Attack/ Dependent Crimes: 1 (100.0%)\n",
      "\n",
      "True Category: Sexually Explicit Act\n",
      "├── Predicted as Online and Social Media Related Crime: 1 (100.0%)\n",
      "\n",
      "Cybercrime Classification Menu:\n",
      "1. Test with custom input\n",
      "2. Test with examples from test dataset\n",
      "3. Exit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your choice (1-3):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thank you for using the Cybercrime Classification System! By Muhammad Mamoon jan\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Dict, List, Union\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.model_name = 'roberta-base'\n",
    "        self.max_length = 512\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.test_path = 'cleaned_cybercrime_test_data.csv'  # Path to test data if available and change to differnt test\n",
    "\n",
    "class CybercrimePredictor:\n",
    "    def __init__(self, model_path: str):\n",
    "        \"\"\"Initialize the predictor with a saved model\"\"\"\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        logger.info(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Load saved model data\n",
    "        logger.info(f\"Loading model from {model_path}\")\n",
    "        saved_data = torch.load(model_path, map_location=self.device)\n",
    "        \n",
    "        # Get configuration\n",
    "        self.config = saved_data['config']\n",
    "        \n",
    "        # Initialize tokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.config.model_name)\n",
    "        \n",
    "        # Initialize model\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            self.config.model_name,\n",
    "            num_labels=len(saved_data['label_encoder'].classes_)\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Load model weights and label encoder\n",
    "        self.model.load_state_dict(saved_data['model_state_dict'])\n",
    "        self.label_encoder = saved_data['label_encoder']\n",
    "        self.model.eval()\n",
    "        \n",
    "        logger.info(\"Model loaded successfully!\")\n",
    "\n",
    "    def predict(self, text: str) -> Tuple[str, float]:\n",
    "        \"\"\"Predict the category of a given text\"\"\"\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.config.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        encoding = {k: v.to(self.device) for k, v in encoding.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**encoding)\n",
    "            probs = F.softmax(outputs.logits, dim=1)\n",
    "            predicted_class = torch.argmax(probs, dim=1).cpu().numpy()[0]\n",
    "            confidence = probs[0][predicted_class].cpu().numpy()\n",
    "        \n",
    "        predicted_category = self.label_encoder.inverse_transform([predicted_class])[0]\n",
    "        return predicted_category, confidence\n",
    "\n",
    "def test_custom_input(predictor: CybercrimePredictor, text: str) -> None:\n",
    "    \"\"\"Test the model with custom user input\"\"\"\n",
    "    predicted_category, confidence = predictor.predict(text)\n",
    "    print(\"\\nPrediction Results:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Input Text: {text}\")\n",
    "    print(f\"Predicted Category: {predicted_category}\")\n",
    "    print(f\"Confidence: {confidence:.2%}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "def test_from_csv(predictor: CybercrimePredictor, csv_path: str, num_samples: Union[int, None] = None) -> None:\n",
    "    \"\"\"Test the model with examples from a CSV file with detailed statistics\"\"\"\n",
    "    test_df = pd.read_csv(csv_path)\n",
    "    \n",
    "    if num_samples:\n",
    "        test_df = test_df.sample(n=min(num_samples, len(test_df)), random_state=42)\n",
    "    \n",
    "    print(f\"\\nTesting {len(test_df)} examples from {csv_path}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    correct = 0\n",
    "    results = []\n",
    "    category_stats = {}\n",
    "    confusion_matrix = {}\n",
    "    \n",
    "    for idx, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Processing examples\"):\n",
    "        text = str(row['crimeaditionalinfo'])\n",
    "        true_category = row['category']\n",
    "        predicted_category, confidence = predictor.predict(text)\n",
    "        \n",
    "        # Initialize statistics\n",
    "        if true_category not in category_stats:\n",
    "            category_stats[true_category] = {'total': 0, 'correct': 0, 'wrong': 0, 'confidences': []}\n",
    "        if true_category not in confusion_matrix:\n",
    "            confusion_matrix[true_category] = {}\n",
    "        if predicted_category not in confusion_matrix[true_category]:\n",
    "            confusion_matrix[true_category][predicted_category] = 0\n",
    "            \n",
    "        # Update statistics\n",
    "        confusion_matrix[true_category][predicted_category] += 1\n",
    "        category_stats[true_category]['total'] += 1\n",
    "        \n",
    "        is_correct = predicted_category == true_category\n",
    "        if is_correct:\n",
    "            correct += 1\n",
    "            category_stats[true_category]['correct'] += 1\n",
    "        else:\n",
    "            category_stats[true_category]['wrong'] += 1\n",
    "            \n",
    "        category_stats[true_category]['confidences'].append(float(confidence))\n",
    "        \n",
    "        results.append({\n",
    "            'text': text[:100] + \"...\" if len(text) > 100 else text,\n",
    "            'true_category': true_category,\n",
    "            'predicted_category': predicted_category,\n",
    "            'confidence': confidence,\n",
    "            'is_correct': is_correct\n",
    "        })\n",
    "    \n",
    "    # Print statistics\n",
    "    print_statistics(results, category_stats, confusion_matrix)\n",
    "\n",
    "def print_statistics(results: List[Dict], category_stats: Dict, confusion_matrix: Dict) -> None:\n",
    "    \"\"\"Print detailed statistics of the model's performance\"\"\"\n",
    "    total = len(results)\n",
    "    correct = sum(1 for r in results if r['is_correct'])\n",
    "    accuracy = (correct / total) * 100\n",
    "    \n",
    "    print(\"\\n=== Overall Statistics ===\")\n",
    "    print(f\"Total Examples: {total}\")\n",
    "    print(f\"Correct Predictions: {correct}\")\n",
    "    print(f\"Wrong Predictions: {total - correct}\")\n",
    "    print(f\"Overall Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    # Category-wise statistics\n",
    "    print(\"\\n=== Category-wise Statistics ===\")\n",
    "    for category, stats in sorted(category_stats.items(), key=lambda x: x[1]['total'], reverse=True):\n",
    "        cat_accuracy = (stats['correct'] / stats['total'] * 100) if stats['total'] > 0 else 0\n",
    "        avg_confidence = sum(stats['confidences']) / len(stats['confidences'])\n",
    "        \n",
    "        print(f\"\\n{category} ({stats['total']} cases):\")\n",
    "        print(f\"├── Correct: {stats['correct']}\")\n",
    "        print(f\"├── Wrong: {stats['wrong']}\")\n",
    "        print(f\"├── Accuracy: {cat_accuracy:.2f}%\")\n",
    "        print(f\"└── Avg Confidence: {avg_confidence:.2f}%\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    print(\"\\n=== Confusion Matrix ===\")\n",
    "    for true_cat in confusion_matrix:\n",
    "        print(f\"\\nTrue Category: {true_cat}\")\n",
    "        for pred_cat, count in sorted(confusion_matrix[true_cat].items(), key=lambda x: x[1], reverse=True):\n",
    "            if count > 0:\n",
    "                percentage = (count / category_stats[true_cat]['total']) * 100\n",
    "                print(f\"├── Predicted as {pred_cat}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "def interactive_testing():\n",
    "    \"\"\"Interactive interface for testing the model\"\"\"\n",
    "    print(\"Initializing Cybercrime Classification System...\")\n",
    "    \n",
    "    try:\n",
    "        model_path = 'final_model.pt'\n",
    "        predictor = CybercrimePredictor(model_path)\n",
    "        \n",
    "        while True:\n",
    "            print(\"\\nCybercrime Classification Menu:\")\n",
    "            print(\"1. Test with custom input\")\n",
    "            print(\"2. Test with examples from test dataset\")\n",
    "            print(\"3. Exit\")\n",
    "            \n",
    "            choice = input(\"\\nEnter your choice (1-3): \")\n",
    "            \n",
    "            if choice == '1':\n",
    "                text = input(\"\\nEnter the text to classify (or 'q' to return to menu): \")\n",
    "                if text.lower() == 'q':\n",
    "                    continue\n",
    "                test_custom_input(predictor, text)\n",
    "                \n",
    "            elif choice == '2':\n",
    "                if not os.path.exists('cleaned_cybercrime_test_data.csv'):\n",
    "                    print(\"\\nTest dataset not found! Please place 'cleaned_cybercrime_test_data.csv' in the current directory.\")\n",
    "                    continue\n",
    "                    \n",
    "                try:\n",
    "                    num_samples = input(\"\\nHow many random examples to test? (press Enter for all): \")\n",
    "                    num_samples = int(num_samples) if num_samples.strip() else None\n",
    "                    test_from_csv(predictor, 'cleaned_cybercrime_test_data.csv', num_samples)\n",
    "                except ValueError:\n",
    "                    print(\"Please enter a valid number\")\n",
    "                \n",
    "            elif choice == '3':\n",
    "                print(\"\\nThank you for using the Cybercrime Classification System! By Muhammad Mamoon jan\")\n",
    "                break\n",
    "                \n",
    "            else:\n",
    "                print(\"Invalid choice! Please enter 1, 2, or 3.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error: {str(e)}\")\n",
    "        logger.error(\"Please make sure all required files are present and valid.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    interactive_testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53cac18-56c4-4af5-8b53-487cc4275d20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71e0f3d-f05f-477c-ac5f-7e6e8841523f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0ebd95-181d-4ad9-8510-b231a7092f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1132d02-88cc-42de-a47e-0e47bc93760b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.7\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba11343-b1e8-493d-8aab-9ef012183a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (C_gpu2)",
   "language": "python",
   "name": "c_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
